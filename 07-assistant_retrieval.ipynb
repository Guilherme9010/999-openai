{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fa1870f",
   "metadata": {},
   "source": [
    "### Assistente de Apostilas (pesquisa em documentos PDFs e responde com contexto restrito)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fede0a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import openai\n",
    "from openai import OpenAI\n",
    "#print(openai.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "e3979daf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#client = openai.Client()   # método antigo (deprecated)\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e3585bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vs_68ab64eee3488191aa5223bd0d05ca90\n"
     ]
    }
   ],
   "source": [
    "#vector_store = client.beta.vector_stores.create(name=\"Tutor de Apostilas\")  # versão anterior (depracated)\n",
    "vector_store = client.vector_stores.create(name=\"Tutor de Apostilas\")\n",
    "print(vector_store.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f851c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pode passar vários arquivos, mas vamos passar, apenas, um arquivo\n",
    "file = [\"files/LLM.pdf\"]\n",
    "file_stream = [open(f, \"rb\") for f in file]\n",
    "#file_batch = client.beta.vector_stores.file_batches.upload_and_poll(        # versão anterior (depracated)\n",
    "file_batch = client.vector_stores.file_batches.upload_and_poll(\n",
    "    vector_store_id = vector_store.id,\n",
    "    files = file_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "8a2297a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'completed'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_batch.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e1f363a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_batch.file_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d4b69400",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Tutor Apostila\",\n",
    "    instructions=\"Você é um tutor especializado em tecnologias emergentes. Você sabe responder perguntas sobre LLMs como OpenAI, HuggingFace, etc. Caso você não encontre as respostas, seja sincero e fale que não sabe responder\",\n",
    "    tools=[{\"type\": \"file_search\"}],\n",
    "    tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
    "    model=\"gpt-4-turbo-preview\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "8a67b977",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pergunta = \"Conforme o documento, o que é o Hugging Face?\"\n",
    "pergunta = \"Conforme o documento, o que é o OpenAI?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9697a5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\3798620811.py:2: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  thread = client.beta.threads.create()\n",
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\3798620811.py:3: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  message = client.beta.threads.messages.create(\n"
     ]
    }
   ],
   "source": [
    "# Criação da Thread\n",
    "thread = client.beta.threads.create()\n",
    "message = client.beta.threads.messages.create(\n",
    "    thread_id = thread.id,\n",
    "    role = \"user\",\n",
    "    content = pergunta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0115aab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\3617845786.py:2: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  run = client.beta.threads.runs.create(\n"
     ]
    }
   ],
   "source": [
    "# Executa a thread\n",
    "run = client.beta.threads.runs.create(\n",
    "    thread_id = thread.id,\n",
    "    assistant_id = assistant.id,\n",
    "    instructions = \"Nome de usuário premium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "3d19e3e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\953612562.py:5: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  run = client.beta.threads.runs.retrieve(\n"
     ]
    }
   ],
   "source": [
    "# Aguarda o thread rodar\n",
    "import time \n",
    "while run.status in [\"queued\",\"in_progress\",\"cancelling\"]:\n",
    "    time.sleep(1)\n",
    "    run = client.beta.threads.runs.retrieve(\n",
    "        thread_id = thread.id,\n",
    "        run_id = run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6847959b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\1930001157.py:3: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  mensagens = client.beta.threads.messages.list(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[Message](data=[Message(id='msg_29Ewg2s37ihoaoFSNIOS864S', assistant_id='asst_D17gPCbaL1CyMmxOiCdRFSYN', attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[FileCitationAnnotation(end_index=694, file_citation=FileCitation(file_id='file-D8oezt7qUE5x3YMuTGgCgc'), start_index=681, text='【4:0†LLM.pdf】', type='file_citation')], value='A OpenAI é descrita no documento fornecido como uma organização que lançou o GPT-3 em 2020, o qual se tornou o maior modelo de linguagem com 175 bilhões de parâmetros, estabelecendo um novo referencial de desempenho para tarefas relacionadas à linguagem. Em 2022, a OpenAI lançou o ChatGPT, transformando o GPT-3 e modelos semelhantes em um serviço amplamente acessível aos usuários através de uma interface web. Isso iniciou um aumento significativo na conscientização pública sobre LLMs (Large Language Models) e IA generativa. A OpenAI também esteve envolvida no lançamento do GPT-4 em 2023, que estabeleceu novos referenciais tanto em tamanho de parâmetros quanto em desempenho【4:0†LLM.pdf】.'), type='text')], created_at=1756063817, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='assistant', run_id='run_L8mB8hcF6801K7UqRrFvYxMY', status=None, thread_id='thread_K2bTr6aKnYJAN3jXbcYf0twL'), Message(id='msg_q0vEiwuKyBDWdEKwPdGdDEgn', assistant_id=None, attachments=[], completed_at=None, content=[TextContentBlock(text=Text(annotations=[], value='Conforme o documento, o que é o OpenAI?'), type='text')], created_at=1756063806, incomplete_at=None, incomplete_details=None, metadata={}, object='thread.message', role='user', run_id=None, status=None, thread_id='thread_K2bTr6aKnYJAN3jXbcYf0twL')], has_more=False, object='list', first_id='msg_29Ewg2s37ihoaoFSNIOS864S', last_id='msg_q0vEiwuKyBDWdEKwPdGdDEgn')\n"
     ]
    }
   ],
   "source": [
    "# Verificar a resposta\n",
    "if run.status == \"completed\":\n",
    "    mensagens = client.beta.threads.messages.list(\n",
    "        thread_id = thread.id\n",
    "    )\n",
    "\n",
    "    print(mensagens)\n",
    "else:\n",
    "    print(f\"Erro: {run.status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b2d51b5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A OpenAI é descrita no documento fornecido como uma organização que lançou o GPT-3 em 2020, o qual se tornou o maior modelo de linguagem com 175 bilhões de parâmetros, estabelecendo um novo referencial de desempenho para tarefas relacionadas à linguagem. Em 2022, a OpenAI lançou o ChatGPT, transformando o GPT-3 e modelos semelhantes em um serviço amplamente acessível aos usuários através de uma interface web. Isso iniciou um aumento significativo na conscientização pública sobre LLMs (Large Language Models) e IA generativa. A OpenAI também esteve envolvida no lançamento do GPT-4 em 2023, que estabeleceu novos referenciais tanto em tamanho de parâmetros quanto em desempenho【4:0†LLM.pdf】.\n"
     ]
    }
   ],
   "source": [
    "print(mensagens.data[0].content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ea345521",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\764390232.py:2: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  run_steps = client.beta.threads.runs.steps.list(\n"
     ]
    }
   ],
   "source": [
    "# Analisando os passos do modelo\n",
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id = thread.id,\n",
    "    run_id = run.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "5652c81c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===Step tool_calls\n",
      "==========\n",
      "File Search query:\n",
      "FileSearch(ranking_options=FileSearchRankingOptions(ranker='default_2024_08_21', score_threshold=0.0), results=[FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.716421568903066, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.6666366860941911, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.4739663451082819, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.413633825409534, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.39315253753892354, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.3248121636458754, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.19664467795247376, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.1547064358928083, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.1253361017552882, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.10138742228964577, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.07010070807299269, content=None, attributes={}), FileSearchResult(file_id='file-D8oezt7qUE5x3YMuTGgCgc', file_name='LLM.pdf', score=0.06577533558249093, content=None, attributes={})])\n",
      "==========\n",
      "\n",
      "===Step message_creation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Naja\\AppData\\Local\\Temp\\ipykernel_2348\\3912564020.py:17: DeprecationWarning: The Assistants API is deprecated in favor of the Responses API\n",
      "  message = client.beta.threads.messages.retrieve(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A OpenAI é descrita no documento fornecido como uma organização que lançou o GPT-3 em 2020, o qual se tornou o maior modelo de linguagem com 175 bilhões de parâmetros, estabelecendo um novo referencial de desempenho para tarefas relacionadas à linguagem. Em 2022, a OpenAI lançou o ChatGPT, transformando o GPT-3 e modelos semelhantes em um serviço amplamente acessível aos usuários através de uma interface web. Isso iniciou um aumento significativo na conscientização pública sobre LLMs (Large Language Models) e IA generativa. A OpenAI também esteve envolvida no lançamento do GPT-4 em 2023, que estabeleceu novos referenciais tanto em tamanho de parâmetros quanto em desempenho【4:0†LLM.pdf】.\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps.data[::-1]:\n",
    "    print(f\"\\n===Step {step.step_details.type}\")\n",
    "    if step.step_details.type == \"tool_calls\":\n",
    "        for tool_call in step.step_details.tool_calls:\n",
    "            print(\"=\" * 10)\n",
    "            if tool_call.type == \"code_interpreter\":\n",
    "                print(\"Code Interpreter input:\")\n",
    "                print(tool_call.code_interpreter.input)\n",
    "            elif tool_call.type == \"file_search\":\n",
    "                print(\"File Search query:\")\n",
    "                print(tool_call.file_search)\n",
    "            else:\n",
    "                print(f\"Tool call de tipo {tool_call.type} não tratado\")\n",
    "            print(\"=\" * 10)\n",
    "\n",
    "    if step.step_details.type == \"message_creation\":\n",
    "        message = client.beta.threads.messages.retrieve(\n",
    "            thread_id=thread.id,\n",
    "            message_id=step.step_details.message_creation.message_id,\n",
    "        )\n",
    "        if message.content[0].type == \"text\":\n",
    "            print(message.content[0].text.value)\n",
    "        if message.content[0].type == \"image_file\":\n",
    "            file_id = message.content[0].image_file.file_id\n",
    "            image_data = client.files.content(file_id)\n",
    "            with open(f\"files/{file_id}.png\", \"wb\") as f:\n",
    "                f.write(image_data.read())\n",
    "                print(f\"Imagem: {file_id} foi salva.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
